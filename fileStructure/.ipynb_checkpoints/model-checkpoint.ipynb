{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30fd547-bb6a-40dd-aed5-f3d22c8fbc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f4dd41-9bc6-41dd-9397-add6dea49712",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    \"surprise\",  # 0\n",
    "    \"fear\",      # 1\n",
    "    \"disgust\",   # 2\n",
    "    \"happy\",     # 3\n",
    "    \"sad\",       # 4\n",
    "    \"angry\",     # 5\n",
    "    \"neutral\"    # 6\n",
    "]\n",
    "NUM_CLASSES = len(LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166f3045-f4ad-4b9a-9d80-8aa11172bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RafDataset(Dataset):\n",
    "    \"\"\"\n",
    "    RAF-DB folder mapping\n",
    "    1: surprise\n",
    "    2: fear\n",
    "    3: disgust\n",
    "    4: happy\n",
    "    5: sad\n",
    "    6: angry\n",
    "    7: neutral\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None, verbose=True):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        for label in range(1, 8):\n",
    "            label_dir = os.path.join(root, str(label))\n",
    "            if not os.path.isdir(label_dir):\n",
    "                if verbose:\n",
    "                    print(f\"[WARN] missing dir: {label_dir}\")\n",
    "                continue\n",
    "\n",
    "            files = [\n",
    "                f for f in os.listdir(label_dir)\n",
    "                if f.lower().endswith(\".jpg\")\n",
    "            ]\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"label {label} -> {len(files)} images\")\n",
    "\n",
    "            for fname in files:\n",
    "                self.samples.append(\n",
    "                    (os.path.join(label_dir, fname), label - 1)\n",
    "                )\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\"No images found in dataset\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbef79d-f715-4f1e-be3a-a5289014f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694136da-13d1-4068-86e6-67cd3b863573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 1 -> 1290 images\n",
      "label 2 -> 281 images\n",
      "label 3 -> 717 images\n",
      "label 4 -> 4772 images\n",
      "label 5 -> 1982 images\n",
      "label 6 -> 705 images\n",
      "label 7 -> 2524 images\n",
      "label 1 -> 329 images\n",
      "label 2 -> 74 images\n",
      "label 3 -> 160 images\n",
      "label 4 -> 1185 images\n",
      "label 5 -> 478 images\n",
      "label 6 -> 162 images\n",
      "label 7 -> 680 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RafDataset(\"DATASET/train\", transform, verbose=True)\n",
    "test_dataset  = RafDataset(\"DATASET/test\",  transform, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1044fc77-744f-4322-9fa5-48a2e29839d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size   = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710944ec-2e54-42d6-8f82-7c1e3a0f7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3c0f5f-00ba-4cdb-987e-b3900657fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "for name, p in model.named_parameters():\n",
    "    if \"layer4\" in name:\n",
    "        p.requires_grad = True\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9062648-f010-4655-9abe-f5541d3ddec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81234808-d1c5-43ac-808c-ed28c49fcdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1232b2-9e22-4231-a4b3-33299b2b7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pred = out.argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e78a3e94-0b2c-43f8-ad04-0b032338289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [10:58<43:52, 658.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | loss 1.051 acc 0.627 | val_loss 0.855 val_acc 0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [20:08<29:44, 594.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | loss 0.502 acc 0.831 | val_loss 0.821 val_acc 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [30:05<19:51, 595.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | loss 0.176 acc 0.956 | val_loss 0.938 val_acc 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [37:40<09:00, 540.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | loss 0.053 acc 0.993 | val_loss 0.979 val_acc 0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [44:30<00:00, 534.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | loss 0.024 acc 0.997 | val_loss 0.937 val_acc 0.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc     = val_one_epoch(model, val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"loss {train_loss:.3f} acc {train_acc:.3f} | \"\n",
    "        f\"val_loss {val_loss:.3f} val_acc {val_acc:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be49e164-47cd-4411-a630-eb812e009b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # [1, 3, 224, 224]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        conf, pred = torch.max(probs, dim=1)\n",
    "\n",
    "    label = LABELS[pred.item()]\n",
    "    confidence = conf.item()\n",
    "\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a43e3388-0a07-41ed-a62f-306cdd222196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_000s_0.jpg -> neutral (0.54)\n",
      "face_005s_0.jpg -> neutral (0.55)\n",
      "face_010s_0.jpg -> happy (0.96)\n",
      "face_015s_0.jpg -> happy (0.57)\n",
      "face_020s_0.jpg -> happy (0.92)\n",
      "face_025s_0.jpg -> happy (0.77)\n",
      "face_030s_0.jpg -> surprise (0.30)\n",
      "face_035s_0.jpg -> happy (0.91)\n",
      "face_040s_0.jpg -> happy (0.78)\n",
      "face_045s_0.jpg -> neutral (0.85)\n",
      "Image_20251205_13608_723 PM.jpg -> surprise (0.80)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = \"app/facial/tmp/faces\"\n",
    "\n",
    "for fname in os.listdir(IMAGE_DIR):\n",
    "    if not fname.lower().endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(IMAGE_DIR, fname)\n",
    "    label, conf = predict_image(path, model)\n",
    "    print(f\"{fname} -> {label} ({conf:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f4c2a5-51e4-47e4-a4f3-afd47d7c2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_MAP = {\n",
    "    \"happy\": \"happiness\",\n",
    "    \"neutral\": \"neutral\",\n",
    "\n",
    "    \"anger\": \"tension\",\n",
    "    \"disgust\": \"tension\",\n",
    "    \"fear\": \"tension\",\n",
    "    \"surprise\": \"tension\",\n",
    "    \"sad\": \"tension\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "638490a7-2e3c-4e1b-98c2-e480cb5a8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_to_state(emotion, confidence, th=0.6):\n",
    "    if confidence < th:\n",
    "        return \"neutral\", confidence\n",
    "\n",
    "    state = STATE_MAP.get(emotion, \"neutral\")\n",
    "    return state, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b610da7e-3982-4d7e-80c3-afd4a1b0d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for fname in sorted(os.listdir(IMAGE_DIR)):\n",
    "    if not fname.lower().endswith(\".jpg\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(IMAGE_DIR, fname)\n",
    "    emotion, conf = predict_image(path, model)\n",
    "\n",
    "    results.append({\n",
    "        \"image\": fname,\n",
    "        \"emotion\": emotion,\n",
    "        \"confidence\": conf\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7815c9d-5b90-4993-baa0-26c14e1521c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3クラス変換結果 ===\n",
      "Image_20251205_13608_723 PM.jpg | surprise  (0.80) -> tension\n",
      "face_000s_0.jpg      | neutral   (0.54) -> neutral\n",
      "face_005s_0.jpg      | neutral   (0.55) -> neutral\n",
      "face_010s_0.jpg      | happy     (0.96) -> happiness\n",
      "face_015s_0.jpg      | happy     (0.57) -> neutral\n",
      "face_020s_0.jpg      | happy     (0.92) -> happiness\n",
      "face_025s_0.jpg      | happy     (0.77) -> happiness\n",
      "face_030s_0.jpg      | surprise  (0.30) -> neutral\n",
      "face_035s_0.jpg      | happy     (0.91) -> happiness\n",
      "face_040s_0.jpg      | happy     (0.78) -> happiness\n",
      "face_045s_0.jpg      | neutral   (0.85) -> neutral\n"
     ]
    }
   ],
   "source": [
    "print(\"=== 3クラス変換結果 ===\")\n",
    "\n",
    "for r in results:\n",
    "    state, conf = emotion_to_state(r[\"emotion\"], r[\"confidence\"])\n",
    "    print(\n",
    "        f\"{r['image']:20s} | \"\n",
    "        f\"{r['emotion']:9s} ({r['confidence']:.2f}) -> {state}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d416e9d-0a50-4aee-aaf1-297f864556f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_tension_window(emotions, min_count=2):\n",
    "    tension_set = {\"anger\",\"disgust\",\"fear\",\"surprise\",\"sad\"}\n",
    "    return sum(e in tension_set for e in emotions) >= min_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f71ab699-0393-4930-8d8f-78b1b55b0c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 時系列 緊張判定 ===\n",
      "00 | ['surprise'] -> tension=False\n",
      "01 | ['surprise', 'neutral'] -> tension=False\n",
      "02 | ['surprise', 'neutral', 'neutral'] -> tension=False\n",
      "03 | ['neutral', 'neutral', 'happy'] -> tension=False\n",
      "04 | ['neutral', 'happy', 'happy'] -> tension=False\n",
      "05 | ['happy', 'happy', 'happy'] -> tension=False\n",
      "06 | ['happy', 'happy', 'happy'] -> tension=False\n",
      "07 | ['happy', 'happy', 'surprise'] -> tension=False\n",
      "08 | ['happy', 'surprise', 'happy'] -> tension=False\n",
      "09 | ['surprise', 'happy', 'happy'] -> tension=False\n",
      "10 | ['happy', 'happy', 'neutral'] -> tension=False\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 3\n",
    "\n",
    "print(\"\\n=== 時系列 緊張判定 ===\")\n",
    "\n",
    "for i in range(len(results)):\n",
    "    window = results[max(0, i-WINDOW+1):i+1]\n",
    "    emotions = [w[\"emotion\"] for w in window]\n",
    "\n",
    "    tension = is_tension_window(emotions)\n",
    "    print(f\"{i:02d} | {[e for e in emotions]} -> tension={tension}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42256edb-76d4-43bd-a880-7c57f91ec331",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"rafdb_resnet18.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573063ad-4401-475c-9982-9a5b741d4e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
